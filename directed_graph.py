#!/usr/bin/python

#author: Ventura Del Monte
#purpose: social networks class project
#last edit: 02/01/2016

from __future__ import division
from collections import defaultdict
import random
import itertools
import math
import sys
import time
import logging
from process_affinity_pool import ProcessPoolExecutorWithAffinity as ProcessPoolExecutor



def euclidean_distance(a, b):
	return math.sqrt(((a[0] - b[0]) ** 2) + ((a[1] - b[1]) ** 2))

def topk(cb, k):
	return sorted(cb.items(), key = lambda x : x[1], reverse=True)[:k]

def lastk(cb, k):
	return sorted(cb.items(), key = lambda x : x[1], reverse=True)[-k:]

def cb_max(cb):
	node = -1
	maxvalue = -1
	for v in cb:
		if cb[v] > maxvalue:
			maxvalue = cb[v]
			node = v
	return (node, maxvalue)


'''
	base class for implementing undirected/directed (optionally weighted) graphs
'''
class DirectedGraph: 
	
	def __init__(self, graph = {}, logger = None):
		self.nodes = graph
		self.__edgesCount = 0
		self.__isWS = False
		self.__isDirected = True
		self.logger = logger

	def setLogger(self, logger):
		self.logger = logger

	def __enter__(self):
		return self

	def __exit__(self, exc_type, exc_value, traceback):
		self.nodes = None
		self.__edgesCount = None
		self.__isWS = None
		self.__isDirected = None

	def setWS(self, mode):
		self.__isWS = mode

	def isWS(self):
		return self.__isWS

	def setDirected(self, mode):
		self.__isDirected = mode

	def isDirected(self):
		return self.__isDirected

	def add_vertex(self, vid):
		if not vid in self.nodes:
			self.nodes[vid] = dict()
			self.nodes[vid]['list'] = set()

	def add_edge(self, fromId, toId):
		self.add_vertex(fromId)
		self.add_vertex(toId)
		if not self.has_edge(fromId, toId):
			self.nodes[fromId]['list'].add(toId)
			self.__edgesCount += 1

	def countTriangles(self):
		triangles = 0
		for t in itertools.combinations(self.nodes.keys(), 3):
			for x in itertools.permutations(t):
				#if x[1] in self.nodes[x[0]] and x[2] in self.nodes[x[1]] and x[2] in self.nodes[x[0]]:
				if self.has_edge(x[0], x[1]) and self.has_edge(x[1], x[2]) and self.has_edge(x[0], x[2]):
					triangles += 1
					break
		return triangles

	def countEdges(self):
		return self.__edgesCount

	def size(self):
		return len(self.nodes), self.__edgesCount

	def diameter(self):
		n = len(self.nodes)
		diameter = -1
		for u in self.nodes: #check the max distance for every node u through BFS
			visited = [] # keep a list of visited nodes to check if the graph is connected
			max_distance = 0 # keep the max distance from u
			queue = [u]
			distances = {u : 0}
			while len(queue) > 0:
				s = queue.pop(0)
				visited.append(s)
				for v in self.nodes[s]['list']:
					if not v in distances:
						queue.append(v)
						distances[v] = distances[s] + 1
						if distances[v] > max_distance:
							max_distance = distances[v]

			if len(visited) < n: # graph is not connected
				break
			elif max_distance > diameter:
				diameter = max_distance

		return diameter	

	def has_edge(self, u, v):
		return v in self.nodes[u]['list']

	def average_clustering(self):
		n = len(self.nodes)
		total = 0.0
		for i in self.nodes:
			triangles = 0.0
			neighbors = self.nodes[i]['list']
			neighbors_count = len(neighbors)
			pairs = float(neighbors_count * (neighbors_count - 1) / 2) #number of pairs of neighbors of node i
			if pairs > 0:
				for t in itertools.permutations(neighbors, 2):
					#number of pairs of neighbors of node i that are adjacent
					if self.has_edge(t[0], t[1]):
						triangles += 1 
				if self.isDirected():
					total += triangles / pairs  
				else:
					total += triangles / (2 * pairs)   # triangles / neighbors is the individual clustering of node i

		return total / n #the average clustering is the average of individual clusterings

	def toUndirect(self):
		ret = DirectedGraph()
		ret.setDirected(False)
		for vertex in self.nodes:
			ret.add_vertex(vertex)
			for oth in self.nodes[vertex]['list']:
				ret.add_vertex(oth)
				ret.nodes[vertex]['list'].add(oth)
				ret.nodes[oth]['list'].add(vertex)
		return ret



	def betweenness(self):
		'''
			this is an indicator of a node's centrality in a network.
			It is equal to the number of shortest paths from all vertices to all others
			that pass through that node. A node with high betweenness centrality has
			a large influence on the transfer of items through the network, 
			under the assumption that item transfer follows the shortest paths.
		'''
		cb = defaultdict(lambda: 0) #betweenness centrality

		for i in self.nodes: #check the max distance for every node i
			visited = [] #keep a list of visited nodes to check if the graph is connected
			P = {}
			sigma = {}
			distances = {}

			# for j in self.nodes:
			# 	P[j] = [] # j's parents list
			# 	sigma[j] = 0
			# 	distances[j] = -1

			P = defaultdict(lambda: [])	
			sigma = defaultdict(lambda: 0)	
			distances = defaultdict(lambda: -1)	 

			sigma[i] = 1
			queue = [i]
			distances[i] = 0

			# BFS
			while len(queue) > 0:
				s = queue.pop(0)
				visited.append(s)
				for j in self.nodes[s]['list']: # foreach neighbor j of s do
					# j found for the first time?
					if distances[j] < 0:
						queue.append(j)
						distances[j] = distances[s] + 1
					# shortest path to j via s?
					if distances[j] == distances[s] + 1:
						sigma[j] += sigma[s]
						P[j].append(s)
			
			# bottom-up
			delta = defaultdict(lambda: 0) #{j: 0 for j in self.nodes}
			# visited returns vertices in order of non-increasing distance from s
			while len(visited) > 0:
				w = visited.pop()
				if len(P[w]) > 0:
					for v in P[w]:
						delta[v] += (float(sigma[v]) / sigma[w]) * (1.0 + delta[w])
				if w != i:
					cb[w] += delta[w]
		return cb

	def betweennessEx(self):
		'''
			--> this version returns also the distance between all nodes! -> for smart computations
			this is an indicator of a node's centrality in a network.
			It is equal to the number of shortest paths from all vertices to all others
			that pass through that node. A node with high betweenness centrality has
			a large influence on the transfer of items through the network, 
			under the assumption that item transfer follows the shortest paths.
		'''
		cb = defaultdict(lambda: 0)	 #betweenness centrality
		D = {} # D[u][v] - dist between u and v
		for i in self.nodes: #check the max distance for every node i
			visited = [] #keep a list of visited nodes to check if the graph is connected
			D[i] = {i : 0}
			P = defaultdict(lambda: [])	
			sigma = defaultdict(lambda: 0)	
			sigma[i] = 1
			queue = [i]

			# BFS
			while len(queue) > 0:
				s = queue.pop(0)
				visited.append(s)
				if len(self.nodes[s]['list']) <= 0:
					continue
				d = D[i][s] + 1
				for j in self.nodes[s]['list']: 
					if not j in D[i]:
						queue.append(j)
						D[i][j] = d
					elif D[i][j] > d:
						D[i][j] = d
					if D[i][j] == d:
						sigma[j] += sigma[s]
						P[j].append(s)
			
			# bottom-up
			delta = defaultdict(lambda: 0) #{j: 0 for j in self.nodes}
			# visited returns vertices in order of non-increasing distance from s
			while len(visited) > 0:
				w = visited.pop()
				if len(P[w]) > 0:
					for v in P[w]:
						delta[v] += (float(sigma[v]) / sigma[w]) * (1.0 + delta[w])
				if w != i:
					cb[w] += delta[w]
		return cb, D

	def parallelBetweennessEx(self):
		'''
			--> this version returns also the distance between all nodes! -> for smart computations
			this is an indicator of a node's centrality in a network.
			It is equal to the number of shortest paths from all vertices to all others
			that pass through that node. A node with high betweenness centrality has
			a large influence on the transfer of items through the network, 
			under the assumption that item transfer follows the shortest paths.
		'''
		cb = defaultdict(lambda: 0)	 #betweenness centrality
		D = {} # D[u][v] - dist between u and v

		def worker_task(i):
			_cb = 0
			visited = [] #keep a list of visited nodes to check if the graph is connected
			_D = {i : 0}
			P = defaultdict(lambda: [])	
			sigma = defaultdict(lambda: 0)	
			sigma[i] = 1
			queue = [i]

			# BFS
			while len(queue) > 0:
				s = queue.pop(0)
				visited.append(s)
				if len(self.nodes[s]['list']) <= 0:
					continue
				d = _D[s] + 1
				for j in self.nodes[s]['list']: 
					if not j in _D:
						queue.append(j)
						_D[j] = d
					elif _D[j] > d:
						_D[j] = d
					if _D[j] == _D[s] + 1:
						sigma[j] += sigma[s]
						P[j].append(s)
			
			# bottom-up
			delta = defaultdict(lambda: 0) #{j: 0 for j in self.nodes}
			# visited returns vertices in order of non-increasing distance from s
			while len(visited) > 0:
				w = visited.pop()
				if len(P[w]) > 0:
					for v in P[w]:
						delta[v] += (float(sigma[v]) / sigma[w]) * (1.0 + delta[w])
				if w != i:
					_cb += delta[w]
			return i, _cb, _D

		with ProcessPoolExecutor() as executor:
			futures = { executor.submit(worker_task, i) for i in self.nodes }
			for future in concurrent.futures.as_completed(futures):
				res = future.result()
				cb[res[0]] = res[1]
				D[res[0]] = res[2]
			
		return cb, D


	def eigenvector_centrality(self, epsilon = 1e-03):
		'''
			Eigenvector centrality is a measure of the influence of a node in a network. 
			It assigns relative scores to all nodes in the network based on the concept 
			that connections to high-scoring nodes contribute more to the score of the node
			in question than equal connections to low-scoring nodes.
		'''
		diff_sum = float('+inf')
		keys = self.nodes.keys()
		cscores = dict.fromkeys(keys, 1.0)

		#i = 0
		while (diff_sum >= epsilon):
			# print i, '. eigenvector_centrality: current error = ', diff_sum
			old_cscores_summation = sum(cscores.values())
			# print 'old_cscores_summation', old_cscores_summation
			tmp = {}
			for node in keys:
				tmp[node] = cscores[node]

				for neigh in self.nodes[node]['list']:
					tmp[node] += cscores[neigh]

			max_neigh_cscore = max(tmp.values())

			# print tmp, max_neigh_cscore
			for node in keys:
				cscores[node] = tmp[node] / max_neigh_cscore

			diff_sum = abs(sum(cscores.values()) - old_cscores_summation)
			#i += 1

		return diff_sum, cscores

	def distance(self, u, v):
		queue = [u]
		distances = {u : 0}
		while len(queue) > 0:
			s = queue.pop(0)
			d = distances[s] + 1
			if len(self.nodes[s]['list']) <= 0:
				continue
			for j in self.nodes[s]['list']:
				if not j in distances:
					queue.append(j)
					distances[j] = d
				if j == v:
					return distances[j]
		return float('+inf')

	def all_pairs_distance_BFS(self):
		D = {} # D[u][v] - dist between u and v
		for v in self.nodes:
			D[v] = {v : 0}
			queue = [v]
			while len(queue) > 0:
				curr = queue.pop(0)
				d = D[v][curr] + 1
				if len(self.nodes[curr]['list']) <= 0:
					continue
				for next in self.nodes[curr]['list']:
					if not next in D[v]:
						queue.append(next)
						D[v][next] = d
					elif D[v][next] > d:
						D[v][next] = d
		return D

	def all_pairs_distance_FW(self):
		max = float('+inf')
		distances = defaultdict(lambda: defaultdict(lambda: max))
		for i in self.nodes:
			distances[i][i] = 0
			for j in self.nodes:
				distances[j][j] = 0
				if self.has_edge(i, j):
					distances[i][j] = 1
				if self.has_edge(j, i):
					distances[j][i] = 1

	
		for k in self.nodes:
			if len(self.nodes[k]['list']) == 0:
				continue
			for i in self.nodes:
				if len(self.nodes[i]['list']) == 0:
					continue
				for j in self.nodes:
					if i == j:
						continue
					target_dist = distances[i][k] + distances[k][j]
					if distances[i][j] > target_dist:
						distances[i][j] = target_dist

		return distances



	def lin_index(self, D = None):
		'''
			it retuns lin's index, which weights closeness using the 
			square of the number of coreachable nodes.
			Nodes with an empty coreachable set have centrality 1 by definition.
			The rationale behind this definitions is the following: first,
			we consider closeness not the inverse of a sum of distances,
			but rather the inverse of the average distance, which entails a
			first multiplication by the number of coreachable nodes. This
			change normalizes closeness across the graph. Now, however,
			we want nodes with a larger coreachable set to be more
			important, given that the average distance is the same, so we
			multiply again by the number of coreachable nodes.
			Lin’s index was somewhat surprisingly ignored in the following
			literature. Nonetheless, it seems to provide a reasonable
			solution for the problems caused by the definition of closeness.
			----------------------------------------------------------------
			The intuition behind closeness is that nodes with a large sum of
			distances are peripheral. By reciprocating the sum, nodes with
			a smaller denominator obtain a larger centrality. We remark
			that for the above definition to make sense, the graph needs
			be strongly connected. Lacking that condition, some of the
			denominators will be 1, resulting in a rank of zero for all
			nodes which cannot coreach the whole graph. One further assumes
			that nodes with an empty coreachable set have centrality 0 by definition.
			These apparently innocuous adjustments, however, introduce a
			strong bias toward nodes with a small coreachable set.
			----------------------------------------------------------------
			the trick to speed up this method consists of storing the
			distances between v and every node reachable by this latter
			using a BFS visit. 
		'''
		L = {}

		if D == None:
			D = self.all_pairs_distance_BFS()
		
		for u in self.nodes:
			reachable = 0.0
			closeness = 0.0
			for v in self.nodes:
				if v != u and u in D[v]:
					reachable += 1
					closeness += D[v][u]
			if closeness <= 0:
				L[u] = 1
			else:
				L[u] = (reachable ** 2) / closeness
			self.nodes[u]['lin'] = L[u]
			self.nodes[u]['closeness'] = closeness
			#print("node {} c={} l={} r={}".format(u, closeness, L[u], reachable))
		return L



	# def lin_indexFW(self):
	# 	# it includes Floyd-Warshall to compute all pairs distances
	# 	max = float('+inf')
	# 	lin = {}
		
	# 	distances = {}
	# 	for i in self.nodes:
	# 		for j in self.nodes:
	# 			if not i in distances:
	# 				distances[i] = defaultdict(lambda: max)
	# 				distances[i][i] = 0
	# 			if not j in distances:
	# 				distances[j] = defaultdict(lambda: max)
	# 				distances[j][j] = 0
	# 			if self.has_edge(i, j):
	# 				distances[i][j] = 1
	# 			if self.has_edge(j, i):
	# 				distances[j][i] = 1

		
	# 	for k in self.nodes:
	# 		if len(self.nodes[k]['list']) == 0:
	# 			continue
	# 		for i in self.nodes:
	# 			for j in self.nodes:
	# 				if i == j or j in self.nodes[i]['list']:
	# 					continue
	# 				target_dist = distances[i][k] + distances[k][j]
	# 				if distances[i][j] > target_dist:
	# 					distances[i][j] = target_dist

		
	# 	for u in self.nodes:
	# 		num = den = 0
	# 		for v in self.nodes: 
	# 			if u == v or len(self.nodes[v]['list']) <= 0:
	# 				continue
	# 			vu = distances[v][u] # self.distance(v, u) #
	# 			if vu < max:
	# 				num += 1
	# 				den += vu

	# 		lin[u] = (num ** 2) / den if den > 0 else 1.0
	# 		self.nodes[u]['lin'] = lin[u]

	#	return lin

	def __ltm_round(self, A, neg_A):
		activated = set()
		for v in neg_A:
			sum = 0.0
			for j in self.nodes[v]['list']:
				if j in A:
					sum += self.nodes[j]['LTMthreshold']
			if sum > self.nodes[v]['LTMthreshold']:
				activated.add(v)
		return activated


	def ltm(self, seeds, rounds = 1):
		'''
		Granovetter - Threshold models of collective behavior.
		'''
		vertices = len(self.nodes)
		for u in self.nodes:
			self.nodes[u]['LTMthreshold'] = random.uniform(0.0, 1.0)

		A = set(seeds)
		neg_A = set(self.nodes.keys()) - A

		round = 0
		while round < rounds and len(A) < vertices:
			activated = self.__ltm_round(A, neg_A)
			if len(activated) <= 0:
				break
			A |= activated
			neg_A -= activated
			round += 1

		return A, neg_A, round



	def __str__(self):
		ret = ""
		for vertex in self.nodes:
			ret += 'Node {}: {}\n'.format(vertex, [x for x in self.nodes[vertex]['list']])
		return ret

	def __getitem__(self, key):
		return self.nodes[key]['list'] if not self.__isWS else self.nodes[key]

	@staticmethod
	def randomDirectedGraph(n, p):
		graph = DirectedGraph({k : {'list': set()} for k in range(n)})
		'''
		for i in range(n):
			for j in range(n):
				if i == j:
					continue
				if random.random() <= p:
					graph.add_edge(i, j)
				if random.random() <= p:
					graph.add_edge(j, i)
		'''
		for edge in itertools.permutations(graph.nodes.keys(), 2):
			if random.random() <= p:
				graph.add_edge(edge[0], edge[1])
		return graph

	@staticmethod
	def randomDirectedBalancedGraph(n, p, edges):
		graph = DirectedGraph({k : {'list': set()} for k in range(n)})
		while edges > 0:
			while True:
				u = random.randint(0, n - 1)
				v = random.randint(0, n - 1)
				if (u != v) and graph.has_edge(u, v):
					break
			# random graph property
			if random.random() <= p:
				graph.add_edge(u, v)
				edges -= 1
		return graph	

	@staticmethod	
	def GenWSGridGraph(n, m, r, k, q=2):
		'''
		@param n: number of nodes
		@param m: number of edges
		@param r : radius of each node (a node u is connected with each other node at distance at most r) - strong ties
		@param k : number of random edges for each node u - weak ties [list] e.g. [0, 5, 10]
		'''
		line = int(math.sqrt(n))
		#Initialization
		graph = DirectedGraph({v : {'list': set()} for v in range(n)})

		while m > 0:
			i = random.randint(0, line - 1)
			#j = random.randint(0, line-1)
			#For each node u, we add an edge to each node at distance at most r from u
			for j in range(line):
				for x in range(r+1): # x is the horizontal offset
					for y in range(r+1-x): # y is the vertical offset. The sum of offsets must be at most r
						if x + y > 0: # The sum of offsets must be at least 1
							target = i * line + j
							if i + x < line:
								dest = (i + x) * line
								destp = dest + (j + y)
								if j + y < line and destp not in graph[target]:
									graph[target].add(destp)
									m -= 1
									if m == 0:
										return graph
								destm = dest + (j - y)
								if j - y >= 0 and destm not in graph[target]:
									graph[target].add(destm)
									m -= 1
									if m == 0:
										return graph
							if i - x >= 0:
								dest = (i - x) * line
								destp = dest + (j + y)
								if j + y < line and destp not in graph[target]:
									graph[target].add(destp)
									m -= 1
									if m == 0:
										return graph
								destm = dest + (j - y)
								if j - y >= 0 and destm not in graph[target]:
									graph[target].add(destm)
									m -= 1
									if m == 0:
										return graph

			#For each node u, we add a node to k randomly chosen nodes
			weak_ties = random.choice(k)
			while weak_ties > 0:
				xt = random.randint(0, line - 1)
				yt = random.randint(0, line - 1)
				target = i * line + j
				dest = xt * line + yt
				if xt * line + yt > n - 1:
					continue 
				if xt != i and yt != j and dest not in graph[target] and random.random() <= (1.0 / (euclidean_distance((xt, yt), (i,j)) ** q)):
					graph[target].add(dest)
					m -= 1
					weak_ties -= 1
					if m == 0:
						return graph
		return graph

	@staticmethod
	def preferentialAttachment(n, d, p):
		'''
		In a Prefential Attachment Graph when a node j is created, its out-links are produced in the following way:
    		- with a probability p, choose a node i uniformly at random and creates an edge from j to i
    		- with a probability 1-p, choose a node l with a proability that is proportional to the l's current in-degree and creates an edge from j to l.
    
    	This is the idea behind the 'Rich get Richer' phenomen

		'''
		I = []
		graph = DirectedGraph()
		for j in range(n):
			graph.add_vertex(j)
			curr_nodes = graph.size()[0]
			if curr_nodes > 1:
				for _ in range(d):
					if random.random() <= p:
						i = random.randint(0, curr_nodes - 1)
						if not graph.has_edge(j, i):
							graph.add_edge(j, i)
							I.append(i)
					elif len(I) > 1:
						l = random.choice(I)
						if not graph.has_edge(j, l) and l != j:
							graph.add_edge(j, l)
							I.append(l)
		return graph

	@staticmethod		
	def WS2DGraph(n, m, r, k):
		'''
		@param n: number of nodes
		@param m: number of edges
		@param r: radius
		@param k: number of random edges [list] e.g. [0, 5, 10]
		'''
		line = int(math.sqrt(n))
		graph = DirectedGraph({v : {'list': set()} for v in range(n)})
		graph.setWS(True)
		#Initialization
		for i in range(n):
			x = random.random()
			y = random.random()
			graph[i]["x"] = x * line
			graph[i]["y"] = y * line

		#For each node u, we add an edge to each node at distance at most r from u
		tot = m
		while m > 0:
			i = random.randint(0, n - 1)
			if len(graph[i]['list']) <= 0:
				for j in range(n):
					#dist = math.sqrt((graph[i]["x"] - graph[j]["x"])**2 + (graph[i]["y"] - graph[j]["y"])**2) # Euclidean distance between i and j
					dist = euclidean_distance((graph[i]["x"], graph[i]["y"]), (graph[j]["x"], graph[j]["y"]))
					if dist <= r and i != j and j not in graph[i]['list']:
						graph[i]['list'].add(j)
						m -= 1
						if m == 0:
							break

				#For each node u, we add a node to k randomly chosen nodes
				weak_ties = random.choice(k)
				while weak_ties > 0:
					s = random.randint(0, n - 1)
					if s == i or s in graph[i]['list']:
						continue
					graph[i]['list'].add(s)
					m -= 1
					weak_ties -= 1
					if m == 0:
						break

		graph.__edgesCount = tot - m
		return graph

	@staticmethod	
	def from_filename(filename, mode = 'd'):
		graph = DirectedGraph()
		if mode == "u":
			graph.setDirected(False) 
		with open(filename) as fp:
			for line in fp:
				if '#' not in line:
					u, v = map(int, line.split())
					graph.add_edge(u, v)
					if mode == "u":
						graph.add_edge(v, u)
		return graph